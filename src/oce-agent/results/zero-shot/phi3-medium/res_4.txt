Based on the provided traces, it appears that the "inference-service-post" operation in the "inference-server" service (process ID p3) has a significantly longer duration compared to its corresponding span in the first trace. In the second trace, this process takes 422967 nanoseconds, while in the first trace it only took 108500 nanoseconds. This indicates that there is an increase in latency during the "inference-service-post" operation of the inference service.
